{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from metric.FENICE import FENICE\n",
    "# fenice = FENICE()\n",
    "\n",
    "\n",
    "\n",
    "# document = '''\n",
    "# Simone Biles’ Olympic return is off to a sparkling start at Paris 2024 as the Americans competed in women’s qualifying Sunday (28 July). The U.S. is well in front with a total team score of 172.296, followed by Italy some 5.435 points back at 166.861. The People’s Republic of China is third with a 166.628.\n",
    "\n",
    "# Reigning world silver medallists Brazil competed in the day’s final subdivision and sit fourth (166.499). In the all-around, Biles, the 2016 gold medallist, scored 59.566 ahead of 2022 world all-around champion Rebeca Andrade (57.700). Reigning champ Suni Lee was third, posting a 56.132. Jordan Chiles earned the fourth highest score at 56.065 but won’t advance to Thursday’s (1 August) all-around final due to two-per-country restrictions. Algeria’s Kaylia Nemour rounds out the top five.\n",
    "\n",
    "# Three years ago, the American withdrew from the women’s team final and four subsequent individual finals at Tokyo 2020 to prioritize her mental health as she dealt with the ‘twisties.’ That seemed like a distant memory Sunday.\n",
    "\n",
    "# Biles, 27, entered Bercy Arena to massive applause, looking relaxed as she smiled and waved to the audience. She looked even more relaxed on the balance beam where in the span of some 79 seconds, she put on a clinic, executing a near flawless routine that included a two layout stepout series and a full-twisting double back dismount. Biles earned a 14.733 for the routine.\n",
    "\n",
    "# In the warm-up for the second rotation on the floor exercise, Biles appeared to tweek her left ankle on her Biles I (double layout half out). When she took to the mat for her competitive routine, her ankle was heavily taped. She delivered a solid, if not bouncy, routine on the event for a 14.666.\n",
    "\n",
    "# As she came off the podium, coach Cecile Landi, a 1996 Olympian for France, asked if she was OK. Biles confirmed she was. But the uncertainty continued through the vault warm-up where at one point she crawled nearly two-thirds of the way back to the starting position before hopping on her right leg.\n",
    "\n",
    "# Later, Biles could be seen waving to her parents, Ron and Nellie, as well as sharing a laugh and several smiles with Landi. When it came time for competition, there was no hint of an issue as she boomed her trademark Yurchenko double pike to the rafters, needing several steps backward to control it. She earned a massive 15.800.\n",
    "\n",
    "# “She felt a little something in her calf. That’s all,” Landi told reporters afterward, adding that Biles was not thinking of leaving the competition. “Never in her mind.” The injury, Landi explained, had popped up a few weeks ago but had subsided in the training leading to Paris. “It felt better at the end [of competition today],” she said later. “On bars, it started to feel better.”\n",
    "\n",
    "# Biles closed out her spectacular on the uneven bars with a hit set and a 14.433, the relief pouring out through her megawatt smile. She embraced coach Laurent Landi before stopping near a scoreboard to soak in the moment. The crowd roared, acknowledging her spectacular return. Before leaving the podium, she blew kisses and waved to her adoring fans.\n",
    "\n",
    "# The American is now set for five of six medal rounds, advancing with the team, in the all-around, and on the vault, beam and floor exercise. “It was pretty amazing. 59.5, and four-for-four. Not perfect,” Landi assessed her pupil’s performance. “She still can improve even.”\n",
    "# '''\n",
    "\n",
    "# summary = 'Simone Biles made a triumphant return to the Olympic stage at the Paris 2024 Games, competing in the women’s gymnastics qualifications. Overcoming a previous struggle with the “twisties” that led to her withdrawal from events at the Tokyo 2020 Olympics, Biles dazzled with strong performances on all apparatus, helping the U.S. team secure a commanding lead in the qualifications. Her routines, including a near-flawless balance beam performance and a powerful Yurchenko double pike vault, showcased her resilience and skill, drawing enthusiastic support from a star-studded audience'\n",
    "\n",
    "# batch = [\n",
    "#     {\"document\": document, \"summary\": summary}\n",
    "# ]\n",
    "\n",
    "# results = fenice.score_batch(batch)\n",
    "# print(results)\n",
    "\n",
    "# [{'score': 0.8484095427307433, 'alignments': [{'score': 0.9968091815244406, 'summary_claim': 'Simone Biles made a triumphant return to the Olympic stage at the Paris 2024 Games.', 'source_passage': '\\n        Simone Biles’ Olympic return is off to a sparkling start at Paris 2024 as the Americans competed in women’s qualifying Sunday (28 July). The U.S. is well in front with a total team score of 172.296, followed by Italy some 5.435 points back at 166.861. The People’s Republic of China is third with a 166.628.\\n    \\n         Reigning world silver medallists Brazil competed in the day’s final subdivision and sit fourth (166.499). In the all-around, Biles, the 2016 gold medallist, scored 59.566 ahead of 2022 world all-around champion Rebeca Andrade (57.700).'}, {'score': 0.9985068442765623, 'summary_claim': 'Biles competed in the women’s gymnastics qualifications.', 'source_passage': '\\n        Simone Biles’ Olympic return is off to a sparkling start at Paris 2024 as the Americans competed in women’s qualifying Sunday (28 July). The U.S. is well in front with a total team score of 172.296, followed by Italy some 5.435 points back at 166.861. The People’s Republic of China is third with a 166.628.\\n    \\n         Reigning world silver medallists Brazil competed in the day’s final subdivision and sit fourth (166.499). In the all-around, Biles, the 2016 gold medallist, scored 59.566 ahead of 2022 world all-around champion Rebeca Andrade (57.700).'}, {'score': 0.9983009036513977, 'summary_claim': \"Biles overcame a previous struggle with the 'twisties' that led to her withdrawal from events at the Tokyo 2020 Olympics.\", 'source_passage': 'Three years ago, the American withdrew from the women’s team final and four subsequent individual finals at Tokyo 2020 to prioritize her mental health as she dealt with the ‘twisties.’ That seemed like a distant memory Sunday.\\n    \\n         Biles, 27, entered Bercy Arena to massive applause, looking relaxed as she smiled and waved to the audience. She looked even more relaxed on the balance beam where in the span of some 79 seconds, she put on a clinic, executing a near flawless routine that included a two layout stepout series and a full-twisting double back dismount. Biles earned a 14.733 for the routine.\\n    \\n        '}, {'score': 0.9821975510567427, 'summary_claim': 'Biles dazzled with strong performances on all apparatus.', 'source_passage': 'DOCUMENT'}, {'score': 0.9991946243681014, 'summary_claim': 'The U.S. team secured a commanding lead in the qualifications.', 'source_passage': '\\n        Simone Biles’ Olympic return is off to a sparkling start at Paris 2024 as the Americans competed in women’s qualifying Sunday (28 July). The U.S. is well in front with a total team score of 172.296, followed by Italy some 5.435 points back at 166.861. The People’s Republic of China is third with a 166.628.\\n    \\n         Reigning world silver medallists Brazil competed in the day’s final subdivision and sit fourth (166.499). In the all-around, Biles, the 2016 gold medallist, scored 59.566 ahead of 2022 world all-around champion Rebeca Andrade (57.700).'}, {'score': 0.9942512132693082, 'summary_claim': 'Her routines showcased her resilience and skill.', 'source_passage': 'DOCUMENT'}, {'score': -0.03039351903134957, 'summary_claim': 'Her routines drew enthusiastic support from a star-studded audience.', 'source_passage': 'Three years ago, the American withdrew from the women’s team final and four subsequent individual finals at Tokyo 2020 to prioritize her mental health as she dealt with the ‘twisties.’'}]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### rouge 만 적용. 전체 document atomic하게 만들고 전체 적용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "# import json\n",
    "# from metric.FENICE import FENICE\n",
    "# import time\n",
    "# fenice = FENICE()\n",
    "\n",
    "# # Load the xsumfaith.json file\n",
    "# with open('../dawon_org/xsumfaith_short.json', 'r', encoding=\"utf-8\") as f:\n",
    "#     xsumfaith_data = json.load(f)\n",
    "# xsumfaith_data = xsumfaith_data[88:]\n",
    "# # JSON 파일을 새로 생성 (초기화)\n",
    "# with open('./fenice_rouge.json', 'w', encoding=\"utf-8\") as f:\n",
    "#     f.write(\"[\\n\")  # JSON 배열 시작\n",
    "# # Compute the scores for each document-summary pair\n",
    "# for i, item in enumerate(xsumfaith_data):\n",
    "#     batch = [{\"document\": item[\"document\"], \"summary\": item[\"claim\"]}]\n",
    "#     result = fenice.score_batch(batch)\n",
    "\n",
    "#     # 저장할 데이터 구조\n",
    "#     result_entry = {\n",
    "#         \"score\": result[0][\"score\"],\n",
    "#         \"label\": item[\"label\"],\n",
    "#         \"document\": item[\"document\"],\n",
    "#         \"summary\": item[\"claim\"]\n",
    "#     }\n",
    "\n",
    "#     # JSON 파일에 한 줄씩 추가 (마지막 요소인지 확인하여 쉼표 처리)\n",
    "#     with open('./fenice_rouge.json', 'a', encoding=\"utf-8\") as f:\n",
    "#         json.dump(result_entry, f, indent=4)\n",
    "#         if i < len(xsumfaith_data) - 1:  # 마지막 요소가 아니면 쉼표 추가\n",
    "#             f.write(\",\\n\")\n",
    "\n",
    "# # JSON 파일 닫기 (배열 닫기)\n",
    "# with open('./fenice_rouge.json', 'a', encoding=\"utf-8\") as f:\n",
    "#     f.write(\"\\n]\")\n",
    "\n",
    "# print(\"Results saved to fenice_original.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import json\n",
    "from metric.FENICE import FENICE\n",
    "import time\n",
    "fenice = FENICE()\n",
    "\n",
    "# Load the xsumfaith.json file\n",
    "with open('../dawon_org/frank_short.json', 'r', encoding=\"utf-8\") as f:\n",
    "    frank_data = json.load(f)\n",
    "frank_data = frank_data[543:]\n",
    "# JSON 파일을 새로 생성 (초기화)\n",
    "# with open('../results/frank/fenice_rouge.json', 'w', encoding=\"utf-8\") as f:\n",
    "#     f.write(\"[\\n\")  # JSON 배열 시작\n",
    "# Compute the scores for each document-summary pair\n",
    "for i, item in enumerate(frank_data):\n",
    "    batch = [{\"document\": item[\"document\"], \"summary\": item[\"claim\"]}]\n",
    "    result = fenice.score_batch(batch)\n",
    "\n",
    "    # 저장할 데이터 구조\n",
    "    result_entry = {\n",
    "        \"score\": result[0][\"score\"],\n",
    "        \"label\": item[\"label\"],\n",
    "        \"document\": item[\"document\"],\n",
    "        \"summary\": item[\"claim\"]\n",
    "    }\n",
    "\n",
    "    # JSON 파일에 한 줄씩 추가 (마지막 요소인지 확인하여 쉼표 처리)\n",
    "    with open('../results/frank/fenice_rouge.json', 'a', encoding=\"utf-8\") as f:\n",
    "        json.dump(result_entry, f, indent=4)\n",
    "        if i < len(frank_data) - 1:  # 마지막 요소가 아니면 쉼표 추가\n",
    "            f.write(\",\\n\")\n",
    "\n",
    "# JSON 파일 닫기 (배열 닫기)\n",
    "with open('../results/frank/fenice_rouge.json', 'a', encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n]\")\n",
    "\n",
    "print(\"Results saved to fenice_original.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import json\n",
    "from metric.FENICE import FENICE\n",
    "import time\n",
    "fenice = FENICE()\n",
    "\n",
    "# Load the xsumfaith.json file\n",
    "with open('../dawon_org/cogensumm_short.json', 'r', encoding=\"utf-8\") as f:\n",
    "    cogensumm_data = json.load(f)\n",
    "cogensumm_data = cogensumm_data[342:]\n",
    "# JSON 파일을 새로 생성 (초기화)\n",
    "# with open('../results/cogensumm/fenice_rouge.json', 'w', encoding=\"utf-8\") as f:\n",
    "#     f.write(\"[\\n\")  # JSON 배열 시작\n",
    "# Compute the scores for each document-summary pair\n",
    "for i, item in enumerate(cogensumm_data):\n",
    "    batch = [{\"document\": item[\"document\"], \"summary\": item[\"claim\"]}]\n",
    "    result = fenice.score_batch(batch)\n",
    "\n",
    "    # 저장할 데이터 구조\n",
    "    result_entry = {\n",
    "        \"score\": result[0][\"score\"],\n",
    "        \"label\": item[\"label\"],\n",
    "        \"document\": item[\"document\"],\n",
    "        \"summary\": item[\"claim\"]\n",
    "    }\n",
    "\n",
    "    # JSON 파일에 한 줄씩 추가 (마지막 요소인지 확인하여 쉼표 처리)\n",
    "    with open('../results/cogensumm/fenice_rouge.json', 'a', encoding=\"utf-8\") as f:\n",
    "        json.dump(result_entry, f, indent=4)\n",
    "        if i < len(cogensumm_data) - 1:  # 마지막 요소가 아니면 쉼표 추가\n",
    "            f.write(\",\\n\")\n",
    "\n",
    "# JSON 파일 닫기 (배열 닫기)\n",
    "with open('../results/cogensumm/fenice_rouge.json', 'a', encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n]\")\n",
    "\n",
    "print(\"Results saved to fenice_original.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### here is no_discards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import json\n",
    "from metric.FENICE import FENICE\n",
    "import time\n",
    "fenice = FENICE()\n",
    "\n",
    "# Load the xsumfaith.json file\n",
    "with open('../dawon_org/xsumfaith_short.json', 'r', encoding=\"utf-8\") as f:\n",
    "    xsumfaith_data = json.load(f)\n",
    "xsumfaith_data = xsumfaith_data#[88:]\n",
    "# JSON 파일을 새로 생성 (초기화)\n",
    "with open('../results/xsumfaith/fenice_rouge_no_discards.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(\"[\\n\")  # JSON 배열 시작\n",
    "# Compute the scores for each document-summary pair\n",
    "for i, item in enumerate(xsumfaith_data):\n",
    "    batch = [{\"document\": item[\"document\"], \"summary\": item[\"claim\"]}]\n",
    "    result = fenice.score_batch(batch)\n",
    "\n",
    "    # 저장할 데이터 구조\n",
    "    result_entry = {\n",
    "        \"score\": result[0][\"score\"],\n",
    "        \"label\": item[\"label\"],\n",
    "        \"document\": item[\"document\"],\n",
    "        \"summary\": item[\"claim\"]\n",
    "    }\n",
    "\n",
    "    # JSON 파일에 한 줄씩 추가 (마지막 요소인지 확인하여 쉼표 처리)\n",
    "    with open('../results/xsumfaith/fenice_rouge_no_discards.json', 'a', encoding=\"utf-8\") as f:\n",
    "        json.dump(result_entry, f, indent=4)\n",
    "        if i < len(xsumfaith_data) - 1:  # 마지막 요소가 아니면 쉼표 추가\n",
    "            f.write(\",\\n\")\n",
    "\n",
    "# JSON 파일 닫기 (배열 닫기)\n",
    "with open('../results/xsumfaith/fenice_rouge_no_discards.json', 'a', encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n]\")\n",
    "\n",
    "print(\"Results saved to fenice_original.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import json\n",
    "from metric.FENICE import FENICE\n",
    "import time\n",
    "fenice = FENICE()\n",
    "\n",
    "# Load the xsumfaith.json file\n",
    "with open('../dawon_org/frank_short.json', 'r', encoding=\"utf-8\") as f:\n",
    "    frank_data = json.load(f)\n",
    "frank_data = frank_data#[88:]\n",
    "# JSON 파일을 새로 생성 (초기화)\n",
    "with open('../results/frank/fenice_rouge_no_discards.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(\"[\\n\")  # JSON 배열 시작\n",
    "# Compute the scores for each document-summary pair\n",
    "for i, item in enumerate(frank_data):\n",
    "    batch = [{\"document\": item[\"document\"], \"summary\": item[\"claim\"]}]\n",
    "    result = fenice.score_batch(batch)\n",
    "\n",
    "    # 저장할 데이터 구조\n",
    "    result_entry = {\n",
    "        \"score\": result[0][\"score\"],\n",
    "        \"label\": item[\"label\"],\n",
    "        \"document\": item[\"document\"],\n",
    "        \"summary\": item[\"claim\"]\n",
    "    }\n",
    "\n",
    "    # JSON 파일에 한 줄씩 추가 (마지막 요소인지 확인하여 쉼표 처리)\n",
    "    with open('../results/frank/fenice_rouge_no_discards.json', 'a', encoding=\"utf-8\") as f:\n",
    "        json.dump(result_entry, f, indent=4)\n",
    "        if i < len(frank_data) - 1:  # 마지막 요소가 아니면 쉼표 추가\n",
    "            f.write(\",\\n\")\n",
    "\n",
    "# JSON 파일 닫기 (배열 닫기)\n",
    "with open('../results/frank/fenice_rouge_no_discards.json', 'a', encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n]\")\n",
    "\n",
    "print(\"Results saved to fenice_original.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import json\n",
    "from metric.FENICE import FENICE\n",
    "import time\n",
    "fenice = FENICE()\n",
    "\n",
    "# Load the xsumfaith.json file\n",
    "with open('../dawon_org/cogensumm_short.json', 'r', encoding=\"utf-8\") as f:\n",
    "    cogensumm_data = json.load(f)\n",
    "cogensumm_data = cogensumm_data#[88:]\n",
    "# JSON 파일을 새로 생성 (초기화)\n",
    "with open('../results/cogensumm/fenice_rouge_no_discards.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(\"[\\n\")  # JSON 배열 시작\n",
    "# Compute the scores for each document-summary pair\n",
    "for i, item in enumerate(cogensumm_data):\n",
    "    batch = [{\"document\": item[\"document\"], \"summary\": item[\"claim\"]}]\n",
    "    result = fenice.score_batch(batch)\n",
    "\n",
    "    # 저장할 데이터 구조\n",
    "    result_entry = {\n",
    "        \"score\": result[0][\"score\"],\n",
    "        \"label\": item[\"label\"],\n",
    "        \"document\": item[\"document\"],\n",
    "        \"summary\": item[\"claim\"]\n",
    "    }\n",
    "\n",
    "    # JSON 파일에 한 줄씩 추가 (마지막 요소인지 확인하여 쉼표 처리)\n",
    "    with open('../results/cogensumm/fenice_rouge_no_discards.json', 'a', encoding=\"utf-8\") as f:\n",
    "        json.dump(result_entry, f, indent=4)\n",
    "        if i < len(cogensumm_data) - 1:  # 마지막 요소가 아니면 쉼표 추가\n",
    "            f.write(\",\\n\")\n",
    "\n",
    "# JSON 파일 닫기 (배열 닫기)\n",
    "with open('../results/cogensumm/fenice_rouge_no_discards.json', 'a', encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n]\")\n",
    "\n",
    "print(\"Results saved to fenice_original.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/venvs/FENICECOARSEvenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/workspace/venvs/FENICECOARSEvenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Extracting claims...: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "splitting document batches into sentences: 100%|██████████| 1/1 [00:00<00:00, 28.73it/s]\n",
      "/workspace/venvs/FENICECOARSEvenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "04/09/2025 03:14:48 - INFO - \t Using default tokenizer.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Extracting claims...: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Trey made the prom-posal in the gym during Ellie's P.E. class.\"]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(factcc_data):\n\u001b[1;32m     18\u001b[0m     batch \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m: item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaim\u001b[39m\u001b[38;5;124m\"\u001b[39m]}]\n\u001b[0;32m---> 19\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfenice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# 저장할 데이터 구조\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     result_entry \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m: item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m: item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaim\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     27\u001b[0m     }\n",
      "File \u001b[0;32m/workspace/venvs/FENICECOARSEvenv/lib/python3.10/site-packages/metric/FENICE.py:187\u001b[0m, in \u001b[0;36mFENICE.score_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    185\u001b[0m documents \u001b[38;5;241m=\u001b[39m [el[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m    186\u001b[0m summaries \u001b[38;5;241m=\u001b[39m [el[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m--> 187\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummaries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample_id, (doc, summary) \u001b[38;5;129;01min\u001b[39;00m tqdm(\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(documents, summaries)),\n\u001b[1;32m    191\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(documents),\n\u001b[1;32m    192\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing FENICE...\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    193\u001b[0m ):\n",
      "File \u001b[0;32m/workspace/venvs/FENICECOARSEvenv/lib/python3.10/site-packages/metric/FENICE.py:210\u001b[0m, in \u001b[0;36mFENICE.cache\u001b[0;34m(self, documents, summaries)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcache\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents, summaries):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m# self.cache_sentences(documents)\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# if self.use_coref:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# 여기 주석해제하고 summary 확인하기ㄴ\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     claims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_claims(summaries)\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_sentences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclaims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclaims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_coref:\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_coref(documents)\n",
      "File \u001b[0;32m/workspace/venvs/FENICECOARSEvenv/lib/python3.10/site-packages/metric/FENICE.py:219\u001b[0m, in \u001b[0;36mFENICE.cache_sentences\u001b[0;34m(self, documents, claims)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcache_sentences\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents, claims):\n\u001b[0;32m--> 219\u001b[0m     modified_all_sentences, original_all_sentences \u001b[38;5;241m=\u001b[39m \u001b[43mdawon_split_into_sentences_batched_no_discards\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclaims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclaims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouge_raio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrouge_ratio\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (mod_sentences, ori_sentences) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(modified_all_sentences, original_all_sentences)):\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_id(i, documents[i])\n",
      "File \u001b[0;32m/workspace/venvs/FENICECOARSEvenv/lib/python3.10/site-packages/metric/utils/utils.py:244\u001b[0m, in \u001b[0;36mdawon_split_into_sentences_batched_no_discards\u001b[0;34m(texts, return_offsets, batch_size, claims, rouge_raio)\u001b[0m\n\u001b[1;32m    242\u001b[0m new_sentences \u001b[38;5;241m=\u001b[39m [(sentence, start_idx, end_idx)]  \u001b[38;5;66;03m# 원본 포함\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mprint\u001b[39m(atomic_facts)\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    245\u001b[0m new_sentences \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [(fact, start_idx, end_idx) \u001b[38;5;28;01mfor\u001b[39;00m fact \u001b[38;5;129;01min\u001b[39;00m atomic_facts]  \u001b[38;5;66;03m# atomic fact 추가\u001b[39;00m\n\u001b[1;32m    246\u001b[0m modified_sentences[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    247\u001b[0m     modified_sentences[\u001b[38;5;241m0\u001b[39m][:idx] \u001b[38;5;241m+\u001b[39m new_sentences \u001b[38;5;241m+\u001b[39m modified_sentences[\u001b[38;5;241m0\u001b[39m][idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    248\u001b[0m )\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import json\n",
    "from metric.FENICE import FENICE\n",
    "import time\n",
    "fenice = FENICE(rouge_ratio=1)\n",
    "\n",
    "# Load the xsumfaith.json file\n",
    "with open('../dawon_org/factcc_short.json', 'r', encoding=\"utf-8\") as f:\n",
    "    factcc_data = json.load(f)\n",
    "factcc_data = factcc_data#[88:]\n",
    "# JSON 파일을 새로 생성 (초기화)\n",
    "with open('../results/factcc/fenice_rouge_no_discards_sametest.json', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(\"[\\n\")  # JSON 배열 시작\n",
    "# Compute the scores for each document-summary pair\n",
    "for i, item in enumerate(factcc_data):\n",
    "    batch = [{\"document\": item[\"document\"], \"summary\": item[\"claim\"]}]\n",
    "    result = fenice.score_batch(batch)\n",
    "\n",
    "    # 저장할 데이터 구조\n",
    "    result_entry = {\n",
    "        \"score\": result[0][\"score\"],\n",
    "        \"label\": item[\"label\"],\n",
    "        \"document\": item[\"document\"],\n",
    "        \"summary\": item[\"claim\"]\n",
    "    }\n",
    "\n",
    "    # JSON 파일에 한 줄씩 추가 (마지막 요소인지 확인하여 쉼표 처리)\n",
    "    with open('../results/factcc/fenice_rouge_no_discards_sametest.json', 'a', encoding=\"utf-8\") as f:\n",
    "        json.dump(result_entry, f, indent=4)\n",
    "        if i < len(factcc_data) - 1:  # 마지막 요소가 아니면 쉼표 추가\n",
    "            f.write(\",\\n\")\n",
    "\n",
    "# JSON 파일 닫기 (배열 닫기)\n",
    "with open('../results/factcc/fenice_rouge_no_discards_sametest.json', 'a', encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n]\")\n",
    "\n",
    "print(\"Results saved to fenice_original.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FENICECOARSEvenv",
   "language": "python",
   "name": "fenicecoarsevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
